const config = require('../config')
const request = require('request')

const shell = require('shelljs')

const fs = require('mz/fs')

const sparqlResultsToArray = require('./sparql-results-to-array')

//const Timer = require('../util/execution-timer')

const spawn = require('child_process').spawn

const tmp = require('tmp-promise')

function escapeSparqlIRI(uri) {

    return '<' + uri + '>';

}

function updateQuery(sparql, graphUri, accept) {

    const triplestoreConfig = config.get('triplestore')

    graphUri = graphUri || triplestoreConfig.defaultGraph

    if (config.get('logSparqlQueries'))
        console.log(sparql)

    return new Promise((resolve, reject) => {

        request({

            method: 'POST',
            url: triplestoreConfig.sparqlEndpoint + '-auth',
            qs: {
                query: sparql,
                'default-graph-uri': graphUri
            },
            auth: {
                user: triplestoreConfig.username,
                pass: triplestoreConfig.password,
                sendImmediately: false
            },
            headers: {
                accept: accept
            }

        }, (err, res, body) => {

            if (err) {
                reject(err)
                return
            }

            if (res.statusCode >= 300) {
                reject(new Error(body))
                return
            }

            resolve({
                type: res.headers['content-type'],
                statusCode: res.statusCode,
                body: body
            })
        })

    })

}

function updateQueryJson(sparql, graphUri) {

    //const timer = Timer('sparql query')

    return updateQuery(sparql, graphUri, 'application/sparql-results+json').then(parseResult)

    function parseResult(res) {

        //timer()

        //console.log('res status code is ' + res.statusCode)

        var results = JSON.parse(res.body)

        return Promise.resolve(sparqlResultsToArray(results))

    }


}

function query(sparql, graphUri, accept) {

    console.log(sparql)

    const triplestoreConfig = config.get('triplestore')

    graphUri = graphUri || triplestoreConfig.defaultGraph

    if (config.get('logSparqlQueries'))
        console.log(sparql)

    return new Promise((resolve, reject) => {

        request({

            method: 'get',
            url: triplestoreConfig.sparqlEndpoint,
            qs: {
                query: sparql,
                'default-graph-uri': graphUri
            },
            headers: {
                accept: accept
            }

        }, (err, res, body) => {

            if (err) {
                reject(err)
                return
            }

            if (res.statusCode >= 300) {
                reject(new Error(body))
                return
            }

            resolve({
                type: res.headers['content-type'],
                statusCode: res.statusCode,
                body: body
            })
        })

    })

}

function queryJson(sparql, graphUri) {

    //const timer = Timer('sparql query')

    return query(sparql, graphUri, 'application/sparql-results+json').then(parseResult)

    function parseResult(res) {

        //timer()

        //console.log('res status code is ' + res.statusCode)

        var results = JSON.parse(res.body)

        return Promise.resolve(sparqlResultsToArray(results))

    }


}

function queryJsonStaggered(sparql, graphUri) {

    var offset = 0
    var limit = config.get('staggeredQueryLimit')

    var resultsUnion = []

    return performQuery()

    function performQuery() {

        console.log('queryJsonStaggered: offset ' + offset + ', limit ' + limit + ', ' + resultsUnion.length + ' results so far')

        return queryJson(sparql + ' OFFSET ' + offset + ' LIMIT ' + limit, graphUri).then((results) => {

            //console.log('qj results')
            //console.log(JSON.stringify(results))

            if (results.length === 0) {

                return Promise.resolve(resultsUnion)

            } else {

                Array.prototype.push.apply(resultsUnion, results)

                offset += limit

                return performQuery()

            }

        })

    }

}

function deleteStaggered(sparql, graphUri) {

    var limit = config.get('staggeredQueryLimit')

    return performQuery()

    function performQuery() {

        console.log('deleteStaggered: limit ' + limit)

        return updateQueryJson(sparql + ' LIMIT ' + limit, graphUri).then((results) => {

            // hacks! delete succeeds even if nothing was deleted, but it
            // does give us a nice message.
            //
            if (results[0]['callret-0'].indexOf('nothing to do') !== -1) {

                return Promise.resolve()

            } else {

                return performQuery()

            }

        })

    }

}

function upload(graphUri, data, type) {

    const triplestoreConfig = config.get('triplestore')

    graphUri = graphUri || triplestoreConfig.defaultGraph

    return new Promise((resolve, reject) => {

        request({

            method: 'POST',
            url: triplestoreConfig.graphStoreEndpoint,
            qs: {
                'graph-uri': graphUri,
            },
            auth: {
                user: triplestoreConfig.username,
                pass: triplestoreConfig.password,
                sendImmediately: false
            },
            headers: {
                'content-type': type
            },
            body: data

        }, (err, res, body) => {

            if (err) {
                reject(err)
                return
            }

            if (res.statusCode >= 300) {
                reject(new Error(body))
                return
            }

            resolve(body)
        })

    })

}

function uploadSmallFile(graphUri, filename, type) {

    const triplestoreConfig = config.get('triplestore')

    graphUri = graphUri || triplestoreConfig.defaultGraph

    return new Promise((resolve, reject) => {

        console.log('sparql upload file: ' + filename)
        console.log('gui ' + graphUri)

        /* TODO: it would be very nice to stream the file to the request
         * instead of loading it all into memory.
         * unfortunately, with auth: { sendImmediately: false }, the file gets
         * streamed to the initial request (which will fail), and then when the
         * retry request with authentication happens requestjs sends content
         * length of 0.
         */
        fs.readFile(filename).then((contents) => {

            const req = request({

                method: 'POST',
                url: triplestoreConfig.graphStoreEndpoint,
                qs: {
                    'graph-uri': graphUri,
                },
                auth: {
                    user: triplestoreConfig.username,
                    pass: triplestoreConfig.password,
                    sendImmediately: false
                },
                headers: {
                    'content-type': type
                },
                body: contents

            }, (err, res, body) => {

                if (err) {
                    reject(err)
                    return
                }

                console.log('uploadfile done; ' + res.statusCode)
                console.log(body)

                if (res.statusCode >= 300) {
                    reject(new Error(body))
                    return
                }

                resolve(body)
            })

        })


    })

}

function uploadFile(graphUri, filename, type) {

    return tmp.dir().then((tempDir) => {

        console.log('file before splitting ' + filename)
        console.log('splitting RDF to n3 in temp dir ' + tempDir.path)

        return new Promise((resolve, reject) => {

            const splitProcess = spawn(__dirname + '/../../scripts/split_to_n3.sh', [
                filename
            ], {
                cwd: tempDir.path
            })

            splitProcess.stderr.on('data', (data) => {

                console.log('[split_to_n3.sh]', data.toString())

            })

            splitProcess.on('close', (exitCode) => {

                if (exitCode !== 0) {
                    reject(new Error('split_to_n3 returned exit code ' + exitCode))
                    return
                }

                resolve(tempDir.path)

            })

        })

    }).then((tempDir) => {

        return fs.readdir(tempDir).then((files) => {

            var filesToUpload = files.filter(
                (filename) => filename.indexOf('upload_') === 0)

            var total = filesToUpload.length

            console.log(filesToUpload + ' chunks to upload')

            return uploadNextFile()

            function uploadNextFile() {

                if (filesToUpload.length > 0) {

                    var nextFile = tempDir + '/' + filesToUpload[0]
                    filesToUpload = filesToUpload.slice(1)

                    console.log('Uploading n3 chunk: ' + nextFile)

                    return uploadSmallFile(graphUri, nextFile, 'text/n3')
                        .then(() => fs.unlink(nextFile))
                        .then(() => uploadNextFile())

                } else {
		    // TODO: cannot simply unlink a directory
                    return //fs.unlink(tempDir);

                }

            }

        })


    })



}

module.exports = {

    escape: require('pg-escape'),
    escapeIRI: escapeSparqlIRI,
    updateQuery: updateQuery,
    updateQueryJson: updateQueryJson,
    query: query,
    queryJson: queryJson,
    queryJsonStaggered: queryJsonStaggered,
    deleteStaggered: deleteStaggered,
    upload: upload,
    uploadFile: uploadFile,
}